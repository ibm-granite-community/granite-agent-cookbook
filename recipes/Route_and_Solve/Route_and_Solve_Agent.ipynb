{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route and Solve Agent  Agent with LangChain, Granite and watsonx.ai\n",
    "\n",
    "In this recipe, you will use the IBM [Granite](https://www.ibm.com/granite) model now available on watsonx.ai to build a Route and Solve Agent. This agent extends the [Function Calling Agent](../Function_Calling/Function_Calling_Agent.ipynb) recipe by introducing a router node that intelligently distributes queries to specialized subagents, each with their own grouped set of tools.\n",
    "\n",
    "The Route and Solve architecture is ideal when you have a large number of tools that can be naturally grouped by category or domain. Instead of presenting all tools to a single agent, the router first determines which category of tools are needed, then routes the query to the appropriate subagent.\n",
    "\n",
    "This approach offers several benefits:\n",
    "- **Reduced tool selection errors**: Subagents only see relevant tools for their domain\n",
    "- **Better scalability**: Easy to add new tool categories as subagents\n",
    "- **Improved reasoning**: Specialized subagents can reason more effectively within their domain\n",
    "- **Clear separation of concerns**: Tools are logically grouped by functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts in Route and Solve Architecture\n",
    "\n",
    "### 1. **Router Node with Tool Calling**\n",
    "The router uses the LLM's native tool-calling capability to determine which subagent should handle the query. Each subagent is represented as an actual callable tool that the router can invoke directly. This is more scalable than traditional routing approaches and leverages the LLM's semantic understanding for intelligent routing decisions.\n",
    "\n",
    "### 2. **Subagents as Callable Tools**\n",
    "Instead of just routing to a subagent name, each subagent is a proper tool that:\n",
    "- Accepts the user query as input\n",
    "- Executes the subagent's internal logic and tools\n",
    "- Returns the actual result\n",
    "- Is invoked directly by the LLM through tool calling\n",
    "\n",
    "Examples:\n",
    "- **Finance Agent Tool**: Accepts a query, executes the finance subagent with its tools, returns stock data\n",
    "- **Weather Agent Tool**: Accepts a query, executes the weather subagent with its tools, returns weather data\n",
    "\n",
    "### 3. **Subagent Implementation**\n",
    "Each subagent is a specialized function calling agent that:\n",
    "- Only has access to tools in its category\n",
    "- Maintains an internal loop structure using LangGraph\n",
    "- Determines if tool calls are needed, executes them, and iterates\n",
    "- Returns the final response to the router\n",
    "\n",
    "### 4. **Scalability**\n",
    "Adding new tool categories is straightforward and modular:\n",
    "1. Define new tools in a new category\n",
    "2. Create a new subagent graph using `create_agent`\n",
    "3. Define a new subagent tool function that wraps the subagent\n",
    "4. Add the tool to the router's tool list\n",
    "5. The router automatically gains the capability without modifying graph structure\n",
    "\n",
    "This is fundamentally more extensible than manually adding nodes and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Flow Diagram\n",
    "\n",
    "![Agent Flow Example](./images/route_solve_flow.png)\n",
    "\n",
    "This diagram shows how queries flow through the Route and Solve agent:\n",
    "1. A user query enters the system at the **Router Node**\n",
    "2. The **Router Node** uses tool calling to analyze the query and determine which tool/subagent to invoke\n",
    "3. The appropriate **Subagent Tool** is invoked directly (Finance Agent Tool or Weather Agent Tool)\n",
    "4. The subagent executes its internal logic, calling domain-specific tools as needed\n",
    "5. The final response is returned to the user\n",
    "\n",
    "Key difference from traditional routing: Subagents are actual callable tools that execute directly, not just routing destinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1. Set up your environment\n",
    "\n",
    "While you can choose from several tools, this recipe is best suited for a Jupyter Notebook. Jupyter Notebooks are widely used within data science to combine code with various data sources such as text, images and data visualizations.\n",
    "\n",
    "You can run this notebook in [Colab](https://colab.research.google.com/), or download it to your system and [run the notebook locally](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started_with_Jupyter_Locally/Getting_Started_with_Jupyter_Locally.md).\n",
    "\n",
    "To avoid Python package dependency conflicts, we recommend setting up a [virtual environment](https://docs.python.org/3/library/venv.html).\n",
    "\n",
    "Note, this notebook is compatible with Python 3.12 and well as Python 3.11, the default in Colab at the time of publishing this recipe. To check your python version, you can run the `!python --version` command in a code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Set up a watsonx.ai instance\n",
    "\n",
    "See [Getting Started with IBM watsonx](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_WatsonX.ipynb) for information on getting ready to use watsonx.ai.\n",
    "\n",
    "You will need three credentials from the watsonx.ai set up to add to your environment: `WATSONX_URL`, `WATSONX_APIKEY`, and `WATSONX_PROJECT_ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Install relevant libraries and set up credentials and the Granite model\n",
    "\n",
    "We'll need a few libraries for this recipe. We will be using LangGraph and LangChain libraries to use Granite on watsonx.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"::group::Install Dependencies\"\n",
    "%pip install uv\n",
    "! uv pip install \"git+https://github.com/ibm-granite-community/utils.git\" \\\n",
    "    langgraph \\\n",
    "    langchain \\\n",
    "    langchain_ibm\n",
    "! echo \"::endgroup::\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the credentials to use watsonx.ai and create the Granite model for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_core.utils.utils import convert_to_secret_str\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = \"ibm/granite-4-h-small\"\n",
    "\n",
    "llm_params = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_completion_tokens\": 200,\n",
    "    \"repetition_penalty\": 1.05,\n",
    "}\n",
    "\n",
    "# --- 1. LLM Initialization (Agent's Brain) ---\n",
    "llm = init_chat_model(\n",
    "    model=model,\n",
    "    model_provider=\"ibm\",\n",
    "    url=convert_to_secret_str(get_env_var(\"WATSONX_URL\")),\n",
    "    apikey=convert_to_secret_str(get_env_var(\"WATSONX_APIKEY\")),\n",
    "    project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    "    params=llm_params,\n",
    ")\n",
    "print(f\"LLM initialized: {model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the functions grouped by category\n",
    "\n",
    "In a Route and Solve agent, tools are organized into logical groups. Each group will be handled by a dedicated subagent. This organization allows the router to determine which category of tools is needed and route the query accordingly.\n",
    "\n",
    "We'll create two categories: **Finance Tools** and **Weather Tools**. In a real-world scenario, you might have more categories such as Database Tools, Email Tools, or API Integration Tools.\n",
    "\n",
    "These tools are sourced from the [Function Calling Agent](../Function_Calling/Function_Calling_Agent.ipynb) recipe to ensure consistency across recipes and enable maximum code reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finance Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.utils.utils import convert_to_secret_str\n",
    "\n",
    "AV_STOCK_API_KEY = convert_to_secret_str(get_env_var(\"AV_STOCK_API_KEY\", \"unset\"))\n",
    "\n",
    "def get_stock_price(ticker: str, date: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the lowest and highest stock prices for a given ticker and date.\n",
    "\n",
    "    Args:\n",
    "        ticker: The stock ticker symbol, for example, \"IBM\".\n",
    "        date: The date in \"YYYY-MM-DD\" format for which you want to get stock prices.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the low and high stock prices on the given date.\n",
    "    \"\"\"\n",
    "    print(f\"Getting stock price for {ticker} on {date}\")\n",
    "\n",
    "    apikey = AV_STOCK_API_KEY.get_secret_value()\n",
    "    if apikey == \"unset\":\n",
    "        print(\"No API key present; using a fixed, predetermined value for demonstration purposes\")\n",
    "        return {\n",
    "            \"low\": \"245.4500\",\n",
    "            \"high\": \"249.0300\"\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        stock_url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={apikey}\"\n",
    "        stock_data = requests.get(stock_url)\n",
    "        data = stock_data.json()\n",
    "        stock_low = data[\"Time Series (Daily)\"][date][\"3. low\"]\n",
    "        stock_high = data[\"Time Series (Daily)\"][date][\"2. high\"]\n",
    "        return {\n",
    "            \"low\": stock_low,\n",
    "            \"high\": stock_high\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching stock data: {e}\")\n",
    "        return {\n",
    "            \"low\": \"none\",\n",
    "            \"high\": \"none\"\n",
    "        }\n",
    "\n",
    "print(\"=== Finance Tools Initialized ===\")\n",
    "print(\"  Tool 1: 'get_stock_price'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_API_KEY = convert_to_secret_str(get_env_var(\"WEATHER_API_KEY\", \"unset\"))\n",
    "\n",
    "def get_current_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches the current weather for a given location (default: San Francisco).\n",
    "\n",
    "    Args:\n",
    "        location: The name of the city for which to retrieve the weather information.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing weather information such as temperature in celsius, weather description, and humidity.\n",
    "    \"\"\"\n",
    "    print(f\"Getting current weather for {location}\")\n",
    "    apikey=WEATHER_API_KEY.get_secret_value()\n",
    "    if apikey == \"unset\":\n",
    "        print(\"No API key present; using a fixed, predetermined value for demonstration purposes\")\n",
    "        return {\n",
    "            \"description\": \"thunderstorms\",\n",
    "            \"temperature\": 25.3,\n",
    "            \"humidity\": 94\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # API request to fetch weather data\n",
    "        weather_url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={apikey}&units=metric\"\n",
    "        weather_data = requests.get(weather_url)\n",
    "        data = weather_data.json()\n",
    "        # Extracting relevant weather details\n",
    "        weather_description = data[\"weather\"][0][\"description\"]\n",
    "        temperature = data[\"main\"][\"temp\"]\n",
    "        humidity = data[\"main\"][\"humidity\"]\n",
    "\n",
    "        # Returning weather details\n",
    "        return {\n",
    "            \"description\": weather_description,\n",
    "            \"temperature\": temperature,\n",
    "            \"humidity\": humidity\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return {\n",
    "            \"description\": \"none\",\n",
    "            \"temperature\": \"none\",\n",
    "            \"humidity\": \"none\"\n",
    "        }\n",
    "\n",
    "print(\"=== Weather Tools Initialized ===\")\n",
    "print(\"  Tool 1: 'get_current_weather'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Route and Solve Agent\n",
    "\n",
    "Now we'll build the Route and Solve agent. This agent consists of:\n",
    "1. A **router node** that analyzes the query and determines which category of tools to use\n",
    "2. Multiple **subagent nodes**, each specialized for a specific tool category\n",
    "3. A **loop mechanism** that allows the router to receive feedback and reroute if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.1: Define the agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    current_subagent: str\n",
    "\n",
    "print(\"State schema defined - Tracks messages and routing decisions for graph flow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2: Create subagent graphs\n",
    "\n",
    "We create separate function calling agents for each tool category using the `create_agent` utility. Each subagent only sees tools relevant to its domain. The `create_agent` function encapsulates the manual graph building (nodes, edges, routing logic), providing a cleaner and more maintainable approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "finance_tools = [get_stock_price]\n",
    "finance_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=finance_tools,\n",
    ")\n",
    "\n",
    "weather_tools = [get_current_weather]\n",
    "weather_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=weather_tools,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Subagents created successfully ===\")\n",
    "print(\"These subagents will be wrapped as callable tools for the router.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.3: Create router tools\n",
    "\n",
    "Before creating the router node, we need to define wrapper functions that represent each subagent as a callable tool. These tools will be used by the router's tool-calling mechanism to make routing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def finance_agent_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute financial queries including stock prices, market data, and financial analysis.\n",
    "    \n",
    "    This tool executes a specialized finance agent that has access to stock price tools.\n",
    "    \n",
    "    Examples of queries this tool handles:\n",
    "    - \"What were the IBM stock prices on 2025-09-05?\"\n",
    "    - \"Get me Microsoft stock data for today\"\n",
    "    - \"Analyze Apple's recent stock performance\"\n",
    "    \n",
    "    Use this tool when the user asks about:\n",
    "    - Stock prices or historical data\n",
    "    - Financial metrics and market information\n",
    "    - Investment-related queries\n",
    "    \"\"\"\n",
    "    # Execute the finance agent with the user query\n",
    "    state = {\"messages\": [HumanMessage(query)], \"current_subagent\": \"\"}\n",
    "    result = finance_agent.invoke(state)\n",
    "    # Extract and return the final response\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "@tool\n",
    "def weather_agent_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute weather queries including current conditions and forecasts.\n",
    "    \n",
    "    This tool executes a specialized weather agent that has access to weather tools.\n",
    "    \n",
    "    Examples of queries this tool handles:\n",
    "    - \"What is the weather in San Francisco?\"\n",
    "    - \"Get me the current weather in London\"\n",
    "    - \"What's the forecast for New York?\"\n",
    "    \n",
    "    Use this tool when the user asks about:\n",
    "    - Current weather conditions\n",
    "    - Weather forecasts\n",
    "    - Climate and atmospheric information\n",
    "    \"\"\"\n",
    "    \n",
    "    state = {\"messages\": [HumanMessage(query)], \"current_subagent\": \"\"}\n",
    "    result = weather_agent.invoke(state)\n",
    "    \n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# Create subagent tools list for LLM tool calling\n",
    "subagent_tools = [finance_agent_tool, weather_agent_tool]\n",
    "\n",
    "print(\"Subagent tools defined as callable functions:\")\n",
    "print(\"  Tool 1: 'finance_agent_tool' - Executes finance agent with stock price queries\")\n",
    "print(\"  Tool 2: 'weather_agent_tool' - Executes weather agent with weather queries\")\n",
    "\n",
    "def router_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Router node that uses tool calling to invoke the appropriate subagent.\n",
    "    \n",
    "    The LLM analyzes the query and decides which tool (subagent) to invoke based on:\n",
    "    - Tool descriptions and examples\n",
    "    - The user query content\n",
    "    - The LLM's understanding of query intent\n",
    "    \n",
    "    Unlike traditional routing, this approach directly calls the subagent tool which\n",
    "    executes the subagent's logic internally, making the architecture more modular\n",
    "    and extensible.\n",
    "    \n",
    "    Returns the state with the subagent's response in messages.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    user_query = messages[-1].content if messages else \"\"\n",
    "    \n",
    "    \n",
    "    llm_with_tools = llm.bind_tools(subagent_tools)\n",
    "    \n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        tool_call = response.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_input = tool_call[\"args\"].get(\"query\", user_query)\n",
    "        \n",
    "        # Execute the appropriate subagent tool by accessing the underlying function\n",
    "        # @tool decorator wraps functions in StructuredTool objects, so we have to access the original function\n",
    "        if tool_name == \"finance_agent_tool\":\n",
    "            result = finance_agent_tool.invoke({\"query\": tool_input})\n",
    "        elif tool_name == \"weather_agent_tool\":\n",
    "            result = weather_agent_tool.invoke({\"query\": tool_input})\n",
    "        else:\n",
    "            result = \"Unknown tool requested.\"\n",
    "        \n",
    "        from langchain_core.messages import AIMessage, ToolMessage\n",
    "        messages = list(messages)\n",
    "        messages.append(response)\n",
    "        messages.append(ToolMessage(content=result, tool_call_id=tool_call[\"id\"]))\n",
    "        \n",
    "        print(f\"[Router]: Query '{user_query[:50]}...' -> Tool called: {tool_name}\")\n",
    "    else:\n",
    "        \n",
    "        from langchain_core.messages import AIMessage\n",
    "        messages = list(messages)\n",
    "        messages.append(response)\n",
    "        print(f\"[Router]: Query '{user_query[:50]}...' -> No tool needed, using LLM knowledge\")\n",
    "    \n",
    "    return State(messages=messages, current_subagent=\"completed\")\n",
    "\n",
    "print(\"Router node defined - Uses tool calling to invoke subagent tools directly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.4: Create ToolNode for automatic tool invocation\n",
    "\n",
    "Create a ToolNode that automatically handles subagent tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import END\n",
    "\n",
    "# Create a ToolNode that automatically handles tool invocation\n",
    "# ToolNode dispatches based on tool_calls in the LLM response\n",
    "tool_node = ToolNode(tools=subagent_tools)\n",
    "\n",
    "print(\"ToolNode created - Automatically handles subagent tool invocation\")\n",
    "\n",
    "def end_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    End node that simply returns the state with the final conversation.\n",
    "    The router has already handled tool execution and added responses to messages.\n",
    "    \"\"\"\n",
    "    return state\n",
    "\n",
    "print(\"End node defined - Completes the workflow\")\n",
    "\n",
    "def route_tools(state: State) -> str:\n",
    "    \"\"\"\n",
    "    Route to tools if the last message contains tool calls, otherwise go to end_node.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "print(\"Route tools function defined - Determines conditional routing logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.5: Build the graph with ToolNode\n",
    "\n",
    "Build the graph using the router node, tool node, and conditional routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Create the graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes - router, tool node, and end node\n",
    "graph_builder.add_node(\"router\", router_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"end_node\", end_node)\n",
    "\n",
    "print(\"Step 1: Nodes added to graph\")\n",
    "print(\"  - router: Invokes LLM with subagent tools\")\n",
    "print(\"  - tools: ToolNode handles automatic tool invocation (no manual if/elif)\")\n",
    "print(\"  - end_node: Returns final state\")\n",
    "\n",
    "# Add edges\n",
    "# Start -> Router (always start with routing)\n",
    "graph_builder.add_edge(START, \"router\")\n",
    "\n",
    "print(\"Step 2: Initial edge configured - START -> router\")\n",
    "\n",
    "# Router -> conditional routing to tools or end_node\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_tools,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: \"end_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Step 3: Conditional edges configured\")\n",
    "print(\"  - router -> tools (if tool calls present)\")\n",
    "print(\"  - router -> end_node (if no tool calls)\")\n",
    "\n",
    "# Tools -> Back to router (loop for multi-step tool use)\n",
    "graph_builder.add_edge(\"tools\", \"router\")\n",
    "\n",
    "print(\"Step 4: Tool loop edge configured - tools -> router\")\n",
    "\n",
    "# End node to END\n",
    "graph_builder.add_edge(\"end_node\", END)\n",
    "\n",
    "print(\"Step 5: Final edge configured - end_node -> END\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"\\nStep 6: Route and Solve Agent graph compiled successfully!\")\n",
    "print(\"\\n=== Graph Structure ===\")\n",
    "print(\"✓ Router node: Invokes LLM with tool binding\")\n",
    "print(\"✓ ToolNode: Automatically dispatches to subagent tools (no manual if/elif)\")\n",
    "print(\"✓ Subagent tools: finance_agent_tool and weather_agent_tool\")\n",
    "print(\"✓ Each subagent: Executes internal agent graph independently\")\n",
    "print(\"✓ Conditional routing: Based on presence of tool_calls\")\n",
    "print(\"✓ Loop: Allows multi-step tool invocation for complex queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Using the Route and Solve Agent\n",
    "\n",
    "Now let's test the agent with various queries that will be routed to different subagents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def route_and_solve_agent(graph, user_input: str):\n",
    "    \"\"\"\n",
    "    Run the Route and Solve agent with a user query.\n",
    "    \n",
    "    The agent will:\n",
    "    1. Route the query to the appropriate subagent\n",
    "    2. Execute the subagent's tools as needed\n",
    "    3. Return the final response\n",
    "    \"\"\"\n",
    "    user_message = HumanMessage(user_input)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(user_message.pretty_repr())\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    input_state = {\"messages\": [user_message], \"current_subagent\": \"\"}\n",
    "    \n",
    "    for event in graph.stream(input_state):\n",
    "        for node_name, node_state in event.items():\n",
    "            if \"messages\" in node_state and node_state[\"messages\"]:\n",
    "                print(f\"[{node_name}] {node_state['messages'][-1].pretty_repr()}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Finance Query\n",
    "\n",
    "Test a query that should be routed to the finance subagent. The query should include both a ticker symbol and a date in YYYY-MM-DD format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_and_solve_agent(graph, \"What were the IBM stock prices on 2025-09-05?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Weather Query\n",
    "\n",
    "Test a query that should be routed to the weather subagent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_and_solve_agent(graph, \"What is the weather in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: General Knowledge Query\n",
    "\n",
    "Test a query that doesn't require any specific tool category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_and_solve_agent(graph, \"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Simplified Implementation with create_agent\n",
    "\n",
    "The Route and Solve pattern shown above can also be implemented more concisely using LangChain's `create_agent` utility, just like the Function_Calling_Agent recipe. This is the simplest way to build a routing agent without manually constructing the graph.\n",
    "\n",
    "Instead of manually building nodes, edges, and routing logic, you can let `create_agent` handle all the complexity internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Using create_agent for maximum simplicity\n",
    "# This automatically handles graph building, tool routing, and ToolNode integration\n",
    "router_agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=subagent_tools,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMPLIFIED ROUTE AND SOLVE AGENT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nRouter agent created using create_agent utility\")\n",
    "print(\"This automatically handles:\")\n",
    "print(\"  ✓ LLM binding with subagent tools\")\n",
    "print(\"  ✓ Tool node creation and management\")\n",
    "print(\"  ✓ Conditional routing logic\")\n",
    "print(\"  ✓ State management and message handling\")\n",
    "\n",
    "def simplified_route_and_solve(router_agent, user_input: str):\n",
    "    \"\"\"\n",
    "    Run the simplified Route and Solve agent using create_agent.\n",
    "    \n",
    "    This demonstrates the most concise way to implement routing.\n",
    "    \"\"\"\n",
    "    user_message = HumanMessage(user_input)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(user_message.pretty_repr())\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    input_state = {\"messages\": [user_message]}\n",
    "    \n",
    "    for event in router_agent.stream(input_state):\n",
    "        for node_name, node_state in event.items():\n",
    "            if \"messages\" in node_state and node_state[\"messages\"]:\n",
    "                print(f\"[{node_name}] {node_state['messages'][-1].pretty_repr()}\")\n",
    "                print()\n",
    "\n",
    "# Test the simplified agent\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTING SIMPLIFIED AGENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "simplified_route_and_solve(router_agent, \"What were the IBM stock prices on 2025-09-05?\")\n",
    "simplified_route_and_solve(router_agent, \"What is the weather in San Francisco?\")\n",
    "simplified_route_and_solve(router_agent, \"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future enhancements to this architecture:\n",
    "\n",
    "**Extensibility:**\n",
    "- **Add new subagents**: Simply define a new tool function that wraps a new subagent - no graph modifications needed\n",
    "- **Multi-domain queries**: Enable the router to call multiple subagent tools sequentially for complex queries\n",
    "- **Tool composition**: Allow subagents to call tools from other domains through shared tool registries\n",
    "\n",
    "**Advanced routing:**\n",
    "- **Confidence scoring**: Have the router evaluate confidence levels before invoking tools\n",
    "- **Feedback loops**: Allow subagents to report back to the router with partial results or fallback options\n",
    "- **Dynamic tool discovery**: Automatically register new subagent tools at runtime without code modifications\n",
    "- **Query disambiguation**: When a query could match multiple tools, use LLM to clarify intent\n",
    "\n",
    "**Optimization:**\n",
    "- **Tool caching**: Cache subagent results for identical queries\n",
    "- **Parallel execution**: Invoke multiple subagent tools concurrently for queries requiring multiple domains\n",
    "- **Cost optimization**: Route simpler queries to lighter models while reserving heavier models for complex tasks\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
