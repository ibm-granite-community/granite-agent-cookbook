{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granite Route and Solve Agent\n",
    "\n",
    "In this recipe, you will use the IBM [Granite](https://www.ibm.com/granite) model now available on watsonx.ai to build a Route and Solve Agent. This agent extends the [Function Calling Agent](../Function_Calling/Function_Calling_Agent.ipynb) recipe by introducing a router node that intelligently distributes queries to specialized subagents, each with their own grouped set of tools.\n",
    "\n",
    "The Route and Solve architecture is ideal when you have a large number of tools that can be naturally grouped by category or domain. Instead of presenting all tools to a single agent, the router first determines which category of tools are needed, then routes the query to the appropriate subagent.\n",
    "\n",
    "This approach offers several benefits:\n",
    "- **Reduced tool selection errors**: Subagents only see relevant tools for their domain\n",
    "- **Better scalability**: Easy to add new tool categories as subagents\n",
    "- **Improved reasoning**: Specialized subagents can reason more effectively within their domain\n",
    "- **Clear separation of concerns**: Tools are logically grouped by functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Define finance tools and subagent\n",
    "finance_tools = [get_stock_price, get_stock_info]\n",
    "finance_llm = llm.bind_tools(finance_tools)\n",
    "print(\"Finance subagent created - Bound with finance tools: get_stock_price, get_stock_info\")\n",
    "\n",
    "# Define weather tools and subagent\n",
    "weather_tools = [get_current_weather, get_weather_forecast]\n",
    "weather_llm = llm.bind_tools(weather_tools)\n",
    "print(\"Weather subagent created - Bound with weather tools: get_current_weather, get_weather_forecast\")\n",
    "\n",
    "# Finance subagent nodes\n",
    "def finance_llm_node(state: State) -> State:\n",
    "    messages = state[\"messages\"]\n",
    "    response_message = finance_llm.invoke(messages)\n",
    "    return State(messages=[response_message], current_subagent=\"finance\")\n",
    "\n",
    "finance_tool_node = ToolNode(tools=finance_tools)\n",
    "print(\"Finance subagent nodes configured - LLM and tool execution nodes ready\")\n",
    "\n",
    "# Weather subagent nodes\n",
    "def weather_llm_node(state: State) -> State:\n",
    "    messages = state[\"messages\"]\n",
    "    response_message = weather_llm.invoke(messages)\n",
    "    return State(messages=[response_message], current_subagent=\"weather\")\n",
    "\n",
    "weather_tool_node = ToolNode(tools=weather_tools)\n",
    "print(\"Weather subagent nodes configured - LLM and tool execution nodes ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Set up your environment\n",
    "\n",
    "While you can choose from several tools, this recipe is best suited for a Jupyter Notebook. Jupyter Notebooks are widely used within data science to combine code with various data sources such as text, images and data visualizations.\n",
    "\n",
    "You can run this notebook in [Colab](https://colab.research.google.com/), or download it to your system and [run the notebook locally](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started_with_Jupyter_Locally/Getting_Started_with_Jupyter_Locally.md).\n",
    "\n",
    "To avoid Python package dependency conflicts, we recommend setting up a [virtual environment](https://docs.python.org/3/library/venv.html).\n",
    "\n",
    "Note, this notebook is compatible with Python 3.12 and well as Python 3.11, the default in Colab at the time of publishing this recipe. To check your python version, you can run the `!python --version` command in a code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Set up a watsonx.ai instance\n",
    "\n",
    "See [Getting Started with IBM watsonx](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_WatsonX.ipynb) for information on getting ready to use watsonx.ai.\n",
    "\n",
    "You will need three credentials from the watsonx.ai set up to add to your environment: `WATSONX_URL`, `WATSONX_APIKEY`, and `WATSONX_PROJECT_ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Install relevant libraries and set up credentials and the Granite model\n",
    "\n",
    "We'll need a few libraries for this recipe. We will be using LangGraph and LangChain libraries to use Granite on watsonx.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"::group::Install Dependencies\"\n",
    "%pip install uv\n",
    "! uv pip install \"git+https://github.com/ibm-granite-community/utils.git\" \\\n",
    "    langgraph \\\n",
    "    langchain \\\n",
    "    langchain_ibm\n",
    "! echo \"::endgroup::\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the credentials to use watsonx.ai and create the Granite model for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_core.utils.utils import convert_to_secret_str\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = \"ibm/granite-4-h-small\"\n",
    "\n",
    "llm_params = {\n",
    "    \"temperature\": 0,\n",
    "    \"max_completion_tokens\": 200,\n",
    "    \"repetition_penalty\": 1.05,\n",
    "}\n",
    "\n",
    "# --- 1. LLM Initialization (Agent's Brain) ---\n",
    "llm = init_chat_model(\n",
    "    model=model,\n",
    "    model_provider=\"ibm\",\n",
    "    url=convert_to_secret_str(get_env_var(\"WATSONX_URL\")),\n",
    "    apikey=convert_to_secret_str(get_env_var(\"WATSONX_APIKEY\")),\n",
    "    project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    "    params=llm_params,\n",
    ")\n",
    "print(f\"LLM initialized: {model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the functions grouped by category\n",
    "\n",
    "In a Route and Solve agent, tools are organized into logical groups. Each group will be handled by a dedicated subagent. This organization allows the router to determine which category of tools is needed and route the query accordingly.\n",
    "\n",
    "We'll create two categories: **Finance Tools** and **Weather Tools**. In a real-world scenario, you might have more categories such as Database Tools, Email Tools, or API Integration Tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finance Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_stock_price(ticker: str) -> str:\n",
    "    \"\"\"Fetches the current or historical stock price for a given ticker symbol (e.g., IBM).\"\"\"\n",
    "    if ticker == \"IBM\":\n",
    "        return \"The current price for IBM is $180.50.\"\n",
    "    elif ticker == \"AAPL\":\n",
    "        return \"The current price for AAPL is $235.80.\"\n",
    "    elif ticker == \"MSFT\":\n",
    "        return \"The current price for MSFT is $442.30.\"\n",
    "    return f\"Stock price for {ticker} not found.\"\n",
    "\n",
    "@tool\n",
    "def get_stock_info(ticker: str) -> str:\n",
    "    \"\"\"Retrieves general information about a stock ticker including name, sector, and market cap.\"\"\"\n",
    "    stock_info = {\n",
    "        \"IBM\": \"IBM (International Business Machines): Technology sector, Market cap: $175B\",\n",
    "        \"AAPL\": \"AAPL (Apple Inc.): Technology sector, Market cap: $2.9T\",\n",
    "        \"MSFT\": \"MSFT (Microsoft): Technology sector, Market cap: $2.4T\",\n",
    "    }\n",
    "    return stock_info.get(ticker.upper(), f\"Information for {ticker} not found.\")\n",
    "\n",
    "print(\"=== Finance Tools Initialized ===\")\n",
    "print(\"  Tool 1: 'get_stock_price'\")\n",
    "print(\"  Tool 2: 'get_stock_info'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a given location (city name).\"\"\"\n",
    "    weather_data = {\n",
    "        \"San Francisco\": \"San Francisco: Partly cloudy, 62°F, 65% humidity\",\n",
    "        \"Boston\": \"Boston: Clear skies, 45°F, 55% humidity\",\n",
    "        \"New York\": \"New York: Rainy, 50°F, 78% humidity\",\n",
    "    }\n",
    "    location_title = location.title()\n",
    "    return weather_data.get(location_title, f\"Weather data for {location} not available.\")\n",
    "\n",
    "@tool\n",
    "def get_weather_forecast(location: str, days: int = 5) -> str:\n",
    "    \"\"\"Provides the weather forecast for a specified city for the next N days (default: 5).\"\"\"\n",
    "    forecasts = {\n",
    "        \"San Francisco\": f\"Next {days} days: Mix of sun and clouds with temps 55-65°F\",\n",
    "        \"Boston\": f\"Next {days} days: Partly cloudy with temps 40-50°F\",\n",
    "        \"New York\": f\"Next {days} days: Rain expected, temps 48-58°F\",\n",
    "    }\n",
    "    location_title = location.title()\n",
    "    return forecasts.get(location_title, f\"Forecast for {location} not available.\")\n",
    "\n",
    "print(\"=== Weather Tools Initialized ===\")\n",
    "print(\"  Tool 1: 'get_current_weather'\")\n",
    "print(\"  Tool 2: 'get_weather_forecast'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Route and Solve Agent\n",
    "\n",
    "Now we'll build the Route and Solve agent. This agent consists of:\n",
    "1. A **router node** that analyzes the query and determines which category of tools to use\n",
    "2. Multiple **subagent nodes**, each specialized for a specific tool category\n",
    "3. A **loop mechanism** that allows the router to receive feedback and reroute if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.1: Define the agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    # The subagent that was routed to\n",
    "    current_subagent: str\n",
    "\n",
    "print(\"State schema defined - Tracks messages and routing decisions for graph flow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2: Create subagent graphs\n",
    "\n",
    "We create separate function calling agents for each tool category. Each subagent only sees tools relevant to its domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Define finance tools and subagent\n",
    "finance_tools = [get_stock_price, get_stock_info]\n",
    "finance_llm = llm.bind_tools(finance_tools)\n",
    "print(\"Finance subagent created - Bound with finance tools: get_stock_price, get_stock_info\")\n",
    "\n",
    "# Define weather tools and subagent\n",
    "weather_tools = [get_current_weather, get_weather_forecast]\n",
    "weather_llm = llm.bind_tools(weather_tools)\n",
    "print(\"Weather subagent created - Bound with weather tools: get_current_weather, get_weather_forecast\")\n",
    "\n",
    "# Finance subagent nodes\n",
    "def finance_llm_node(state: State) -> State:\n",
    "    messages = state[\"messages\"]\n",
    "    response_message = finance_llm.invoke(messages)\n",
    "    return State(messages=[response_message], current_subagent=\"finance\")\n",
    "\n",
    "finance_tool_node = ToolNode(tools=finance_tools)\n",
    "print(\"Finance subagent nodes configured - LLM and tool execution nodes ready\")\n",
    "\n",
    "# Weather subagent nodes\n",
    "def weather_llm_node(state: State) -> State:\n",
    "    messages = state[\"messages\"]\n",
    "    response_message = weather_llm.invoke(messages)\n",
    "    return State(messages=[response_message], current_subagent=\"weather\")\n",
    "\n",
    "weather_tool_node = ToolNode(tools=weather_tools)\n",
    "print(\"Weather subagent nodes configured - LLM and tool execution nodes ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.3: Create the router node\n",
    "\n",
    "The router analyzes the user query and determines which subagent category should handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def router_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Router node that analyzes the query and routes to the appropriate subagent.\n",
    "    \n",
    "    Returns the state with a routing decision in the current_subagent field.\n",
    "    The returned value should be 'finance', 'weather', or 'end' (for non-tool queries).\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    user_query = messages[-1].content if messages else \"\"\n",
    "    \n",
    "    # Create a prompt for the router to classify the query\n",
    "    router_prompt = f\"\"\"You are a router that directs queries to specialized agents.\n",
    "\n",
    "Available agents:\n",
    "- finance: Handles stock prices, market information, and financial queries\n",
    "- weather: Handles weather forecasts, current weather, and climate information\n",
    "\n",
    "Analyze the following query and respond with ONLY the agent name (finance, weather, or none).\n",
    "If the query doesn't clearly fit any agent, respond with 'none'.\n",
    "\n",
    "Query: {user_query}\n",
    "\n",
    "Agent:\"\"\"\n",
    "    \n",
    "    # Call the model to make routing decision\n",
    "    router_messages = [SystemMessage(content=\"You are a router. Respond with only the agent name: finance, weather, or none.\"),\n",
    "                      HumanMessage(content=router_prompt)]\n",
    "    response = llm.invoke(router_messages)\n",
    "    routing_decision = response.content.strip().lower()\n",
    "    \n",
    "    # Normalize the response\n",
    "    if \"finance\" in routing_decision:\n",
    "        route = \"finance\"\n",
    "    elif \"weather\" in routing_decision:\n",
    "        route = \"weather\"\n",
    "    else:\n",
    "        route = \"none\"\n",
    "    \n",
    "    print(f\"[Router]: Routing decision - {route}\")\n",
    "    return State(messages=messages, current_subagent=route)\n",
    "\n",
    "print(\"Router node defined - Analyzes queries and routes to appropriate subagent\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
